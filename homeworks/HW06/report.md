# HW06 – Report

## 1. Dataset

* **Датасет выбран:** `S06-hw-dataset-02.csv`
* **Размер:** (строк, столбцов) — 5 rows × 39 columns
* **Целевая переменная:** `target` (0: 74%, 1: 26%)
* **Признаки:** числовые и/или категориальные-подобные (указать, какие типы признаков есть, например, 10 числовых и 2 категориальных)

---

## 2. Protocol

* **Разбиение:** train/test - 80/20, `random_state=42`
* **Подбор:** GridSearchCV на RandomForest, 5 фолдов (cv=5), оптимизация ROC-AUC
* **Метрики:**

  * `accuracy` — общая точность предсказаний
  * `F1-score` — чувствителен к несбалансированности классов
  * `ROC-AUC` — оценка способности модели различать классы (ROC-AUC оптимизировалась при подборе гиперпараметров)

Эти метрики уместны, так как мы оцениваем как общий результат (accuracy), так и качество классификации редкого класса (F1 и ROC-AUC).

---

## 3. Models

Сравнивались следующие модели:

* **DummyClassifier** — базовый бейзлайн, случайное угадывание
* **LogisticRegression** — линейная модель, бейзлайн из S05
* **DecisionTreeClassifier** — контроль сложности через `max_depth` и `min_samples_leaf`
* **RandomForestClassifier** — ансамбль деревьев, подбор `n_estimators`, `max_features`, `min_samples_leaf`
* **GradientBoostingClassifier** — контролируемая конфигурация (опционально можно AdaBoost)

Опционально: StackingClassifier с CV-логикой (не использовался в текущем эксперименте).

Гиперпараметры для RandomForest (лучшей модели):

```json
{
    "max_depth": null,
    "max_features": "sqrt",
    "min_samples_leaf": 1,
    "n_estimators": 400
}
```

---

## 4. Results

| Model                       | Accuracy | F1-score | ROC-AUC |
| --------------------------- | -------- | -------- | ------- |
| RandomForest_best           | 0.8922   | 0.7602   | 0.9287  |
| GradientBoosting_controlled | 0.8700   | 0.7090   | 0.8994  |
| DecisionTree_controlled     | 0.8094   | 0.5653   | 0.8093  |
| LogisticRegression          | 0.8119   | 0.5607   | 0.7977  |
| DummyClassifier             | 0.7375   | 0.0000   | 0.5000  |

**Победитель:** RandomForest (по ROC-AUC = 0.9287)
**Объяснение:** Наиболее высокая способность различать классы, лучшая F1 для редкого класса, высокая стабильность.

---

## 5. Analysis

* **Устойчивость:** при изменении `random_state` (5 прогонов) ROC-AUC для RandomForest изменяется в диапазоне 0.927–0.929, среднее значение 0.929. Это показывает высокую стабильность модели.
* **Ошибки:** confusion matrix для RandomForest:

![Confusion Matrix - Random Forest](artifacts/figures/confusion_matrix_rf_best.png)

Комментарий: большая часть ошибок приходится на редкий класс, что объясняется его меньшей долей в выборке.

* **Интерпретация:** permutation importance (топ-10 признаков) показала, что модель опирается на несколько ключевых числовых признаков.
  **Выводы:** важные признаки сильно влияют на предсказание, а менее значимые — могут быть опущены без потери качества.

---

## 6. Conclusion

1. RandomForest — наилучший выбор для данного датасета, с высокой точностью и ROC-AUC.
2. GradientBoosting и DecisionTree — альтернативы, но уступают ансамблевым методам.
3. LogisticRegression — хорошее базовое решение, лучше бейзлайна, но уступает ансамблям.
4. DummyClassifier — демонстрирует случайное угадывание, используется для проверки качества моделей.
5. Ансамбли деревьев обеспечивают баланс между точностью и устойчивостью к переобучению.
6. Честный ML-протокол с разделением train/test и CV помогает корректно оценить модели.
